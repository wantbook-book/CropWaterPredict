{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vgg16 import VGG16\n",
    "from models.mlp import MLP\n",
    "from models.encoder import TransformerEncoder\n",
    "from utils.config_manager import ConfigManager\n",
    "from pathlib import Path\n",
    "from dataset.dataset import CropInfoDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "config = ConfigManager()\n",
    "VGG_WEIGHTS_PATH = str('model_weights/vgg16.bin')\n",
    "class WaterPredictModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaterPredictModel, self).__init__()\n",
    "        vgg16_conf = config.get('vgg16')\n",
    "        self.vgg16 = VGG16(VGG_WEIGHTS_PATH, num_classes=vgg16_conf['output_dim'])\n",
    "        self.data_config = timm.data.resolve_model_data_config(self.vgg16.model)\n",
    "        \n",
    "        encoder_conf = config.get('encoder')\n",
    "        input_dim, d_model, nhead, nhid, nlayers, dropout = \\\n",
    "            encoder_conf['input_dim'], encoder_conf['d_model'], encoder_conf['nhead'],\\\n",
    "                 encoder_conf['nhid'], encoder_conf['nlayers'], encoder_conf['dropout']\n",
    "        self.transformer = TransformerEncoder(\n",
    "            input_dim=input_dim, d_model=d_model, nhead=nhead, nhid=nhid, nlayers=nlayers, dropout=dropout\n",
    "        )\n",
    "        mlp_conf = config.get('mlp')\n",
    "        input_dim, hidden_dim, output_dim = \\\n",
    "            mlp_conf['input_dim'], mlp_conf['hidden_dim'], mlp_conf['output_dim']\n",
    "        self.mlp = MLP(input_size=input_dim, hidden_size=hidden_dim, num_classes=output_dim)\n",
    "    def get_transformer(self, is_training=False):\n",
    "        return timm.data.create_transform(**self.data_config, is_training=is_training)\n",
    "    def forward(self, image, t_T_data):\n",
    "        image_embd = self.vgg16(image)\n",
    "        t_T_embd = self.transformer(t_T_data)\n",
    "        # print(image_embd.shape)\n",
    "        # print(t_T_embd.shape)\n",
    "        embd = torch.cat((image_embd, t_T_embd), dim=1)\n",
    "        return self.mlp(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\onedrive\\桌面\\毕业设计\\算法\\venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WaterPredictModel(\n",
       "  (vgg16): VGG16(\n",
       "    (model): VGG(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace=True)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace=True)\n",
       "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (18): ReLU(inplace=True)\n",
       "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (20): ReLU(inplace=True)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace=True)\n",
       "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (25): ReLU(inplace=True)\n",
       "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (27): ReLU(inplace=True)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (29): ReLU(inplace=True)\n",
       "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (pre_logits): ConvMlp(\n",
       "        (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (head): ClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Identity()\n",
       "        (flatten): Identity()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  )\n",
       "  (transformer): TransformerEncoder(\n",
       "    (encoder): Linear(in_features=3, out_features=512, bias=True)\n",
       "    (pos_encoder): PositionalEncoding()\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WaterPredictModel().to(device)\n",
    "dataset = CropInfoDataset('dataset/preprocess/rgb_images_list.json', 'dataset/preprocess/t_T_mo_data.json', transform=model.get_transformer(is_training=False))\n",
    "test_dataloader = DataLoader(dataset, batch_size=2, shuffle=False, num_workers=1)\n",
    "# 示例代码\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0769],\n",
      "        [-0.0820]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for images, t_T_moisture, labels in test_dataloader:  # 假设test_dataloader是测试数据\n",
    "        images, t_T_moisture = images.to(device), t_T_moisture.to(device)\n",
    "        outputs = model(images, t_T_moisture)\n",
    "        print(outputs)\n",
    "        break\n",
    "        # 进行预测处理，例如取最大概率的标签等"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
